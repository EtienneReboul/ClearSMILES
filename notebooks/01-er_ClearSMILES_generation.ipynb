{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from rdkit import Chem\n",
    "import re\n",
    "import numpy as np \n",
    "import pyarrow.parquet as pq\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERN =  \"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|_|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "SMILES_REGEX = re.compile(PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_biggest_digits(smiles=str()):\n",
    "    \"\"\"\n",
    "    find the biggest digits by iterating throught possible max digits and test if there is a match in string\n",
    "    input: smiles (string)\n",
    "    output: max_digit (integer)\n",
    "    \"\"\"\n",
    "\n",
    "    ### iterate through max digits possible solution\n",
    "    for i in range(1,10):\n",
    "        digit=10-i\n",
    "        if smiles.find(str(digit))!=-1:\n",
    "            return digit\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semantic_mem_map(smiles=str(),SMILES_REGEX=re.compile) -> np.array : \n",
    "    \"\"\"\n",
    "    This function will generate a semantic memory map of a SMILES, i.e the number of semantic feature open for every token. \n",
    "    Semantic feature include  branches and  rings \n",
    "        smiles (string) : a valid SMILES \n",
    "        SMILES_REGEX (compiled regular expression): compiled regular expression used to tokenize SMILES\n",
    "        bonds_set (set of strings): a set containing all the bonds tokens\n",
    "    output :\n",
    "        mem_map  (numpy array):  the semantic memory map of the input SMILES\n",
    "    \"\"\"\n",
    "\n",
    "    ### declare local variables\n",
    "    tokens_list=SMILES_REGEX.findall(smiles)\n",
    "    mem_map= np.zeros(len(tokens_list),dtype=int)\n",
    "    digit_set=set()\n",
    "\n",
    "    ### iterate throught tokens \n",
    "    for i,token in enumerate(tokens_list):\n",
    "        if token==\"(\":\n",
    "            mem_map[i]+= 1\n",
    "        elif token==\")\":\n",
    "            mem_map[i]-=1\n",
    "        elif token.isdigit():\n",
    "            if token in digit_set:\n",
    "                digit_set.remove(token)\n",
    "                mem_map[i]-= 1\n",
    "            else:\n",
    "                digit_set.add(token)\n",
    "                mem_map[i]+= 1\n",
    "   \n",
    "    return mem_map.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'C'),\n",
       " (0, 'C'),\n",
       " (0, 'C'),\n",
       " (0, 'S'),\n",
       " (1, '('),\n",
       " (1, '='),\n",
       " (1, 'O'),\n",
       " (0, ')'),\n",
       " (0, 'c'),\n",
       " (1, '1'),\n",
       " (1, 'c'),\n",
       " (1, 'c'),\n",
       " (1, 'c'),\n",
       " (2, '2'),\n",
       " (2, '[nH]'),\n",
       " (2, 'c'),\n",
       " (3, '('),\n",
       " (3, '='),\n",
       " (3, 'N'),\n",
       " (3, 'C'),\n",
       " (4, '('),\n",
       " (4, '='),\n",
       " (4, 'O'),\n",
       " (3, ')'),\n",
       " (3, 'O'),\n",
       " (3, 'C'),\n",
       " (2, ')'),\n",
       " (2, '[nH]'),\n",
       " (2, 'c'),\n",
       " (1, '2'),\n",
       " (1, 'c'),\n",
       " (0, '1')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### sanity check\n",
    "mem_map= get_semantic_mem_map(\"CCCS(=O)c1ccc2[nH]c(=NC(=O)OC)[nH]c2c1\",SMILES_REGEX=SMILES_REGEX)\n",
    "compared_list= list(zip(mem_map,SMILES_REGEX.findall(\"CCCS(=O)c1ccc2[nH]c(=NC(=O)OC)[nH]c2c1\")))\n",
    "compared_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ClearSMILES(smiles : str, nb_random : int, SMILES_REGEX : re.compile(\"\")) -> dict :\n",
    "    \"\"\"\n",
    "    This function will get a set of ClearSMILES, this is a stochastic process, thus the number of ClearSMILES may vary. \n",
    "    A high number of random search  should yield a stable number of ClearSMILES\n",
    "    input :\n",
    "        smiles (string): a valid SMILES \n",
    "        nb_random (integer): the number of randomized kekule SMILES to generate, i.e the number of random search\n",
    "        SMILES_REGEX (compiled regex):  regex pattern used to tokenize SMILES \n",
    "    output: \n",
    "    results dict with string as keys and  various type of values \n",
    "        smiles and nb_random  input are passed in the result\n",
    "        max digit (integer), indicating the lowest maximum digit found in random SMILES\n",
    "        lowest_mem_score (float), indicates the lowest score obtained by one or more ClearSMILES, currently the mean of semantic memory per token\n",
    "        nb_unique_random_smiles (integer), number of unique randomized kekule SMILES found by random search \n",
    "        nb_lowest_max_digit_smiles (integer), number of randomized kekule SMILES with the lowest max digit found\n",
    "        nb_equivalent_solution  (integer) , which indicate the number of solution which achieved the lowest memory score \n",
    "        ClearSMILES_set, value is (string): concatenation of the ClearSMILES_set as a string using \"_\" as a separator \n",
    "        all keys including keyword time contains the duration of each stage of the pipeline, and value associated are float\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    ### declare local variable \n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    lowest_digit_smiles_set= set()\n",
    "    lowest_mem_score_smiles_set=set()\n",
    "    results_dict={\n",
    "        \"smiles\" : smiles,\n",
    "        \"nb_random\" : nb_random,\n",
    "        \"max_digit\" : 9 ,\n",
    "        \"lowest_mem_score\" : np.inf,\n",
    "        \"nb_unique_random_smiles\" : int,\n",
    "        \"nb_lowest_max_digit_smiles\" : int,\n",
    "        \"nb_equivalent_solution\" : 0,\n",
    "        \"ClearSMILES_set\" : str,\n",
    "        \"random_gen_time\" : float,\n",
    "        \"min_max_digit_time\" : float,\n",
    "        \"mem_map_time\" : float,\n",
    "        \"total_time\" : time.perf_counter(), # neglect the time to instantiate mol + empty sets\n",
    "    }\n",
    "\n",
    "    ### generate randomized kekule SMILES\n",
    "    start_time= time.perf_counter()\n",
    "    randomized_kekule_smiles_set= set(Chem.MolToRandomSmilesVect(mol,nb_random, kekuleSmiles=True))\n",
    "    results_dict[\"nb_unique_random_smiles\"]= len(randomized_kekule_smiles_set)\n",
    "    results_dict[\"random_gen_time\"]= time.perf_counter() -start_time\n",
    "\n",
    "    ### find SMILES with lowest maximum digit\n",
    "    start_time= time.perf_counter() \n",
    "    for rd_smiles in randomized_kekule_smiles_set:\n",
    "\n",
    "        ### declare loop variable \n",
    "        temp_max_digit= find_biggest_digits(rd_smiles)\n",
    "\n",
    "        ### if a new minimum is reach clear the set\n",
    "        if temp_max_digit < results_dict[\"max_digit\"]: \n",
    "            lowest_digit_smiles_set.clear()\n",
    "            results_dict[\"max_digit\"]=temp_max_digit\n",
    "\n",
    "        ### discard smiles if above current threshold\n",
    "        elif temp_max_digit > results_dict[\"max_digit\"]:\n",
    "            continue\n",
    "\n",
    "        lowest_digit_smiles_set.add(rd_smiles)\n",
    "    results_dict[\"nb_lowest_max_digit_smiles\"]= len(lowest_digit_smiles_set)\n",
    "    results_dict[\"min_max_digit_time\"]= time.perf_counter() -start_time    \n",
    "    \n",
    "    ### Keep SMILES with lowest maximum digit for which the semantic memory score is minimal\n",
    "    start_time= time.perf_counter() \n",
    "    for ld_smiles in lowest_digit_smiles_set:\n",
    "\n",
    "        ### declare loop variable\n",
    "        mem_map = get_semantic_mem_map(ld_smiles,SMILES_REGEX)\n",
    "        temp_mem_score= np.mean(mem_map)\n",
    "\n",
    "        ### if a new minimum is reached, clear the set\n",
    "        if temp_mem_score< results_dict[\"lowest_mem_score\"] :\n",
    "            lowest_mem_score_smiles_set.clear()\n",
    "            results_dict[\"lowest_mem_score\"]= temp_mem_score\n",
    "\n",
    "        ### discard SMILES if mem score threshold is passed \n",
    "        elif temp_mem_score > results_dict[\"lowest_mem_score\"]:\n",
    "            continue\n",
    "        \n",
    "        lowest_mem_score_smiles_set.add(ld_smiles)\n",
    "    results_dict[\"mem_map_time\"]= time.perf_counter() -start_time  \n",
    "    \n",
    "    ### concatenate found ClearSMILES as string\n",
    "    results_dict[\"ClearSMILES_set\"] = \"_\".join(lowest_mem_score_smiles_set)\n",
    "    results_dict[\"nb_equivalent_solution\"]= len(lowest_mem_score_smiles_set)\n",
    "\n",
    "    ### compute total time duration \n",
    "    results_dict[\"total_time\"]= time.perf_counter() - results_dict[\"total_time\"]\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict= get_ClearSMILES(\"CC1=CC=C(C=C1)C2=CC(=NN2C3=CC=C(C=C3)S(=O)(=O)N)C(F)(F)F\",nb_random=1_00_000,SMILES_REGEX=SMILES_REGEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'smiles': 'CC1=CC=C(C=C1)C2=CC(=NN2C3=CC=C(C=C3)S(=O)(=O)N)C(F)(F)F',\n",
       " 'nb_random': 100000,\n",
       " 'max_digit': 1,\n",
       " 'lowest_mem_score': 1.1428571428571428,\n",
       " 'nb_unique_random_smiles': 13212,\n",
       " 'nb_lowest_max_digit_smiles': 4370,\n",
       " 'nb_equivalent_solution': 8,\n",
       " 'ClearSMILES_set': 'C1=CC(C)=CC=C1C1=CC(C(F)(F)F)=NN1C1=CC=C(C=C1)S(N)(=O)=O_C1C=C(C)C=CC=1C1=CC(C(F)(F)F)=NN1C1=CC=C(C=C1)S(=O)(N)=O_O=S(N)(=O)C1=CC=C(C=C1)N1N=C(C(F)(F)F)C=C1C1=CC=C(C)C=C1_C1=CC(C)=CC=C1C1=CC(C(F)(F)F)=NN1C1=CC=C(C=C1)S(=O)(N)=O_O=S(=O)(N)C1=CC=C(C=C1)N1N=C(C(F)(F)F)C=C1C1C=CC(C)=CC=1_O=S(=O)(N)C1=CC=C(C=C1)N1N=C(C(F)(F)F)C=C1C1=CC=C(C)C=C1_O=S(N)(=O)C1=CC=C(C=C1)N1N=C(C(F)(F)F)C=C1C1C=CC(C)=CC=1_C1C=C(C)C=CC=1C1=CC(C(F)(F)F)=NN1C1=CC=C(C=C1)S(N)(=O)=O',\n",
       " 'random_gen_time': 3.6964971139996123,\n",
       " 'min_max_digit_time': 0.01838030099952448,\n",
       " 'mem_map_time': 0.07313390200033609,\n",
       " 'total_time': 3.788021114000003}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
